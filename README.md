# CharlesDeGaulle-GPT

## Introduction

This repository contains a version of GPT-2 finetuned on data extracted from Charles De Gaulle's speeches during and after WW2. The GPT-2 model used is a version further pretrained on a large heterogeneous French corpus (~60Gb).
    
## Table of Contents

- [Data Collection](#Data-Collection)
- [Training](#Training)

## Graph Class

<table>
<tr>
<td>
  
<p align="center">
<img src="https://github.com/tlemenestrel/CharlesDeGaulle-GPT/blob/main/data/cdg.png" width="700">
</p>

</td>
</tr>
</table>

## Data Collection

## Training
